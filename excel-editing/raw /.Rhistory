# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Function to forecast exogenous variables
forecast_exog <- function(ts_data) {
# Fit ARIMA model
fit <- auto.arima(ts_data)
# Forecast next value (February 2025)
forecast <- forecast(fit, h = 1)
# Return the forecasted value
return(forecast$mean[1])
}
# Function to prepare exogenous variables
prepare_exog <- function(data, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(data[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Return as a matrix (required for SARIMAX)
return(matrix(exog_feb2025, nrow = 1))
}
# Function to fit SARIMAX model and predict egg prices
predict_egg_price <- function(data, exog_columns) {
# Prepare target variable (egg prices)
ts_eggs <- ts(data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average,
start = c(2006, 1), frequency = 12)
# Prepare exogenous variables
exog_vars <- as.matrix(data[, exog_columns])
# Fit SARIMAX model
fit <- auto.arima(ts_eggs, seasonal = TRUE, xreg = exog_vars)
# Forecast exogenous variables for February 2025
exog_feb2025 <- prepare_exog(data, exog_columns)
# Predict egg prices for February 2025
forecast_eggs <- forecast(fit, h = 1, xreg = exog_feb2025)
# Return the forecasted value
return(forecast_eggs$mean[1])
}
# Load data
df <- read_excel('~/Optiver-Challenge/excel-editing/dataset.xlsx')
# Prepare data
df<- df[, c("date", "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")]
df$date <- as.Date(data$date)
# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Function to forecast exogenous variables
forecast_exog <- function(ts_data) {
# Fit ARIMA model
fit <- auto.arima(ts_data)
# Forecast next value (February 2025)
forecast <- forecast(fit, h = 1)
# Return the forecasted value
return(forecast$mean[1])
}
# Function to prepare exogenous variables
prepare_exog <- function(data, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(data[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Return as a matrix (required for SARIMAX)
return(matrix(exog_feb2025, nrow = 1))
}
# Function to fit SARIMAX model and predict egg prices
predict_egg_price <- function(data, exog_columns) {
# Prepare target variable (egg prices)
ts_eggs <- ts(data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average,
start = c(2006, 1), frequency = 12)
# Prepare exogenous variables
exog_vars <- as.matrix(data[, exog_columns])
# Fit SARIMAX model
fit <- auto.arima(ts_eggs, seasonal = TRUE, xreg = exog_vars)
# Forecast exogenous variables for February 2025
exog_feb2025 <- prepare_exog(data, exog_columns)
# Predict egg prices for February 2025
forecast_eggs <- forecast(fit, h = 1, xreg = exog_feb2025)
# Return the forecasted value
return(forecast_eggs$mean[1])
}
# Load data
df <- read_excel('~/Optiver-Challenge/excel-editing/dataset.xlsx')
# Prepare data
df<- df[, c("date", "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")]
df$date <- as.Date(df$date)
# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Function to forecast exogenous variables
forecast_exog <- function(ts_data) {
# Fit ARIMA model
fit <- auto.arima(ts_data)
# Forecast next value (February 2025)
forecast <- forecast(fit, h = 1)
# Return the forecasted value
return(forecast$mean[1])
}
# Function to prepare exogenous variables
prepare_exog <- function(data, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(data[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Return as a matrix (required for SARIMAX)
return(matrix(exog_feb2025, nrow = 1))
}
# Function to fit SARIMAX model and predict egg prices
predict_egg_price <- function(data, exog_columns) {
# Prepare target variable (egg prices)
ts_eggs <- ts(data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average,
start = c(2006, 1), frequency = 12)
# Prepare exogenous variables
exog_vars <- as.matrix(data[, exog_columns])
# Fit SARIMAX model
fit <- auto.arima(ts_eggs, seasonal = TRUE, xreg = exog_vars)
# Forecast exogenous variables for February 2025
exog_feb2025 <- prepare_exog(data, exog_columns)
# Predict egg prices for February 2025
forecast_eggs <- forecast(fit, h = 1, xreg = exog_feb2025)
# Return the forecasted value
return(forecast_eggs$mean[1])
}
# Load data
df <- read_excel('~/Optiver-Challenge/excel-editing/dataset.xlsx')
# Prepare data
df <- df[, c("date", "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")]
df$date <- as.Date(df$date)  # This should now work
library(readxl)
# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Load data
df <- read_excel('~/Optiver-Challenge/excel-editing/dataset.xlsx')
# Prepare data
df <- df[, c("date", "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")]
df$date <- as.Date(df$date)
# Function to forecast exogenous variables
forecast_exog <- function(ts_data) {
# Fit ARIMA model
fit <- auto.arima(ts_data)
# Forecast next value (February 2025)
forecast <- forecast(fit, h = 1)
# Return the forecasted value
return(forecast$mean[1])
}
# Function to prepare exogenous variables
prepare_exog <- function(df, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(df[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Function to prepare exogenous variables
prepare_exog <- function(df, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(df[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Return as a matrix (required for SARIMAX)
return(matrix(exog_feb2025, nrow = 1))
}
# Function to fit SARIMAX model and predict egg prices
predict_egg_price <- function(df, exog_columns) {
# Prepare target variable (egg prices)
ts_eggs <- ts(df$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average,
start = c(2006, 1), frequency = 12)
# Prepare exogenous variables
exog_vars <- as.matrix(df[, exog_columns])
# Fit SARIMAX model
fit <- auto.arima(ts_eggs, seasonal = TRUE, xreg = exog_vars)
# Forecast exogenous variables for February 2025
exog_feb2025 <- prepare_exog(df, exog_columns)
# Predict egg prices for February 2025
forecast_eggs <- forecast(fit, h = 1, xreg = exog_feb2025)
# Return the forecasted value
return(forecast_eggs$mean[1])
}
# Define exogenous variables
exog_columns <- c("Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")
# Predict egg prices for February 2025
egg_price_feb2025 <- predict_egg_price(df, exog_columns)
print(paste("Predicted egg price for February 2025:", egg_price_feb2025))
# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Load libraries
library(forecast)
library(tseries)
library(ggplot2)
library(readxl)
# Function to forecast exogenous variables
forecast_exog <- function(ts_data) {
# Fit ARIMA model
fit <- auto.arima(ts_data)
# Forecast next value (February 2025)
forecast <- forecast(fit, h = 1)
# Return the forecasted value
return(forecast$mean[1])
}
# Function to prepare exogenous variables
prepare_exog <- function(df, exog_columns) {
# Initialize a vector to store forecasted values
exog_feb2025 <- numeric(length(exog_columns))
# Loop through each exogenous variable
for (i in seq_along(exog_columns)) {
# Extract the column and convert to time series
ts_data <- ts(df[[exog_columns[i]]], start = c(2006, 1), frequency = 12)
# Forecast February 2025 value
exog_feb2025[i] <- forecast_exog(ts_data)
}
# Return as a matrix (required for SARIMAX)
return(matrix(exog_feb2025, nrow = 1))
}
# Function to fit SARIMAX model and predict egg prices
predict_egg_price <- function(df, exog_columns) {
# Prepare target variable (egg prices)
ts_eggs <- ts(df$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average,
start = c(2006, 1), frequency = 12)
# Prepare exogenous variables
exog_vars <- as.matrix(df[, exog_columns])
# Fit SARIMAX model
fit <- auto.arima(ts_eggs, seasonal = TRUE, xreg = exog_vars)
# Forecast exogenous variables for February 2025
exog_feb2025 <- prepare_exog(df, exog_columns)
# Predict egg prices for February 2025
forecast_eggs <- forecast(fit, h = 1, xreg = exog_feb2025)
# Return the forecasted value
return(forecast_eggs$mean[1])
}
# Load data
df <- read_excel('~/Optiver-Challenge/excel-editing/dataset.xlsx')
# Prepare data
df <- df[, c("date", "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")]
df$date <- as.Date(df$date)
# Define exogenous variables
exog_columns <- c("Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Unemployment_Rate", "US_Regular_All_Formulations_Gas_Price")
# Predict egg prices for February 2025
egg_price_feb2025 <- predict_egg_price(df, exog_columns)
print(paste("Predicted egg price for February 2025:", egg_price_feb2025))
# Install Keras and TensorFlow
install.packages("keras")
library(keras)
install_keras()  # Ensure TensorFlow is installed
# Install Keras and TensorFlow
install.packages("keras")
library(keras)
install_keras()  # Ensure TensorFlow is installed
# Install Boruta if necessary
install.packages("Boruta")
library(Boruta)
# Load your dataset
data <- read_excel('~/Optiver-Challenge/data/processed/merged_dataset_imputed.xlsx')
View(data)
colnames(data)
# Install Boruta if necessary
install.packages("Boruta")
library(Boruta)
# Load your dataset
data <- read_excel('~/Optiver-Challenge/data/processed/merged_dataset_imputed.xlsx')
colnames(data)
# Ensure the response variable (y) and features (X) are ready
y <- data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average
X <- data[, c("Average_Price_Chicken_Breast_Boneless_Cost_per_Pound4536_Grams_in_US_City_Average",                                             "Average_Price_Chicken_Fresh_Whole_Cost_per_Pound4536_Grams_in_US_City_Average",
"Average_Price_Milk_Fresh_Whole_Fortified_Cost_per_Gallon38_Liters_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_All_Items_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Energy_Services_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Federal_Funds_Effective_Rate",
"Personal_Consumption_Expenditures",
"Producer_Price_Index_by_Commodity_Farm_Products_Corn",
"Producer_Price_Index_by_Commodity_Farm_Products_Soybeans",
"Producer_Price_Index_by_Commodity_Processed_Foods_and_Feeds_Chicken_and_Turkey_Feed_Supplements__________Concentrates_and_Premixes",
"Real_Disposable_Personal_Income",
"Retail_Sales_Restaurants_and_Other_Eating_Places",
"Retail_Sales_Retail_Trade_and_Food_Services",
"Unemployment_Rate",
"University_of_Michigan_Consumer_Sentiment",
"US_Diesel_Sales_Price",
"US_Regular_All_Formulations_Gas_Price")] # Add your predictors
install.packages("Boruta")
# Load your dataset
data <- read_excel('~/Optiver-Challenge/data/processed/merged_dataset_imputed.xlsx')
colnames(data)
# Ensure the response variable (y) and features (X) are ready
y <- data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average
X <- data[, c("Average_Price_Chicken_Breast_Boneless_Cost_per_Pound4536_Grams_in_US_City_Average",                                             "Average_Price_Chicken_Fresh_Whole_Cost_per_Pound4536_Grams_in_US_City_Average",
"Average_Price_Milk_Fresh_Whole_Fortified_Cost_per_Gallon38_Liters_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_All_Items_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Energy_Services_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Federal_Funds_Effective_Rate",
"Personal_Consumption_Expenditures",
"Producer_Price_Index_by_Commodity_Farm_Products_Corn",
"Producer_Price_Index_by_Commodity_Farm_Products_Soybeans",
"Producer_Price_Index_by_Commodity_Processed_Foods_and_Feeds_Chicken_and_Turkey_Feed_Supplements__________Concentrates_and_Premixes",
"Real_Disposable_Personal_Income",
"Retail_Sales_Restaurants_and_Other_Eating_Places",
"Retail_Sales_Retail_Trade_and_Food_Services",
"Unemployment_Rate",
"University_of_Michigan_Consumer_Sentiment",
"US_Diesel_Sales_Price",
"US_Regular_All_Formulations_Gas_Price")] # Add your predictors
# Step 1: Run Boruta Feature Selection
set.seed(123)  # For reproducibility
boruta_result <- Boruta(X, y, doTrace = 2, maxRuns = 100)  # maxRuns increases accuracy
# Load your dataset
data <- read_excel('~/Optiver-Challenge/data/processed/feature_selection.xlsx')
# Ensure the response variable (y) and features (X) are ready
y <- data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average
X <- data[, c("Average_Price_Chicken_Breast_Boneless_Cost_per_Pound4536_Grams_in_US_City_Average",                                             "Average_Price_Chicken_Fresh_Whole_Cost_per_Pound4536_Grams_in_US_City_Average",
"Average_Price_Milk_Fresh_Whole_Fortified_Cost_per_Gallon38_Liters_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_All_Items_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Energy_Services_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Federal_Funds_Effective_Rate",
"Personal_Consumption_Expenditures",
"Producer_Price_Index_by_Commodity_Farm_Products_Corn",
"Producer_Price_Index_by_Commodity_Farm_Products_Soybeans",
"Producer_Price_Index_by_Commodity_Processed_Foods_and_Feeds_Chicken_and_Turkey_Feed_Supplements__________Concentrates_and_Premixes",
"Real_Disposable_Personal_Income",
"Retail_Sales_Restaurants_and_Other_Eating_Places",
"Retail_Sales_Retail_Trade_and_Food_Services",
"Unemployment_Rate",
"University_of_Michigan_Consumer_Sentiment",
"US_Diesel_Sales_Price",
"US_Regular_All_Formulations_Gas_Price")] # Add your predictors
# Step 1: Run Boruta Feature Selection
set.seed(123)  # For reproducibility
boruta_result <- Boruta(X, y, doTrace = 2, maxRuns = 100)  # maxRuns increases accuracy
# Step 2: Check Boruta Output
print(boruta_result)
# Step 3: Confirm Selected Features
final_boruta <- TentativeRoughFix(boruta_result)
important_features <- getSelectedAttributes(final_boruta, withTentative = FALSE)
cat("Selected Features by Boruta: ", important_features, "\n")
# Step 4: Create a Reduced Dataset with Boruta Features
X_selected <- X[, important_features]
# Step 5: Combine Selected Features with the Target
final_data <- cbind(Egg_Price = y, X_selected)
# Step 6: Save the Final Dataset for SARIMA
write.csv(final_data, "boruta_selected_features.csv", row.names = FALSE)
# Step 1: Run Boruta Feature Selection
set.seed(123)  # For reproducibility
boruta_result <- Boruta(X, y, doTrace = 2, maxRuns = 200)  # maxRuns increases accuracy
# Step 2: Check Boruta Output
print(boruta_result)
# Step 3: Confirm Selected Features
final_boruta <- TentativeRoughFix(boruta_result)
important_features <- getSelectedAttributes(final_boruta, withTentative = FALSE)
cat("Selected Features by Boruta: ", important_features, "\n")
# Step 4: Create a Reduced Dataset with Boruta Features
X_selected <- X[, important_features]
# Step 5: Combine Selected Features with the Target
final_data <- cbind(Egg_Price = y, X_selected)
# Step 6: Save the Final Dataset for SARIMA
write.csv(final_data, "boruta_selected_features.csv", row.names = FALSE)
install.packages("glmnet")
library(glmnet)
# Install Boruta if necessary
install.packages("glmnet")
library(glmnet)
# Load your dataset
data <- read_excel('~/Optiver-Challenge/data/processed/feature_selection.xlsx')
# Ensure the response variable (y) and features (X) are ready
y <- data$Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average
X <- data[, c("Average_Price_Chicken_Breast_Boneless_Cost_per_Pound4536_Grams_in_US_City_Average",                                             "Average_Price_Chicken_Fresh_Whole_Cost_per_Pound4536_Grams_in_US_City_Average",
"Average_Price_Milk_Fresh_Whole_Fortified_Cost_per_Gallon38_Liters_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_All_Items_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Energy_Services_in_US_City_Average",
"Consumer_Price_Index_for_All_Urban_Consumers_Food_in_US_City_Average",
"Federal_Funds_Effective_Rate",
"Personal_Consumption_Expenditures",
"Producer_Price_Index_by_Commodity_Farm_Products_Corn",
"Producer_Price_Index_by_Commodity_Farm_Products_Soybeans",
"Producer_Price_Index_by_Commodity_Processed_Foods_and_Feeds_Chicken_and_Turkey_Feed_Supplements__________Concentrates_and_Premixes",
"Real_Disposable_Personal_Income",
"Retail_Sales_Restaurants_and_Other_Eating_Places",
"Retail_Sales_Retail_Trade_and_Food_Services",
"Unemployment_Rate",
"University_of_Michigan_Consumer_Sentiment",
"US_Diesel_Sales_Price",
"US_Regular_All_Formulations_Gas_Price")] # Add your predictors
install.packages("glmnet")
# Step 3: Fit the Lasso model (with cross-validation)
set.seed(123)  # For reproducibility
lasso_model <- cv.glmnet(as.matrix(X), y, alpha = 1)  # alpha=1 for Lasso (Ridge uses alpha=0)
# Step 4: Get the best lambda (penalty)
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
# Step 5: Coefficients for the selected features
lasso_coef <- coef(lasso_model, s = "lambda.min")
print(lasso_coef)
# Step 6: Identify the non-zero coefficients (selected features)
selected_features <- rownames(lasso_coef)[lasso_coef != 0]
# Step 3: Fit the Lasso model (with cross-validation)
set.seed(123)  # For reproducibility
lasso_model <- cv.glmnet(as.matrix(X), y, alpha = 1)  # alpha=1 for Lasso (Ridge uses alpha=0)
# Step 4: Get the best lambda (penalty)
best_lambda <- lasso_model$lambda.min
cat("Best lambda: ", best_lambda, "\n")
# Step 5: Coefficients for the selected features
lasso_coef <- coef(lasso_model, s = "lambda.min")
print(lasso_coef)
# Step 6: Identify the non-zero coefficients (selected features)
lasso_coef_matrix <- as.matrix(lasso_coef)  # Convert to a regular matrix
selected_features <- rownames(lasso_coef_matrix)[lasso_coef_matrix != 0]
cat("Selected Features by Lasso: ", selected_features, "\n")
library(readxl)
library(xgboost)
# Libraries
library(readxl)
install.packages("xgboost")
library(xgboost)
install.packages("randomForest")
library(randomForest)
setwd("~/Optiver-Challenge/data/processed")
# Read the dataset (ensure the file is in your working directory)
data <- read_excel("merged_dataset_imputed.xlsx")
# Convert the date column to Date type (adjust the format if needed)
data$date <- as.Date(data$date)
# Define the target variable name as it appears in your dataset
target_col <- "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average"
# Define predictor names by excluding the date and target columns
predictor_names <- setdiff(names(data), c("date", target_col))
# Create the matrix of predictors and ensure column names are set
X <- as.matrix(data[, predictor_names])
colnames(X) <- predictor_names
# Extract the target variable
y <- data[[target_col]]
# Create a DMatrix for xgboost training
dtrain <- xgb.DMatrix(data = X, label = y)
# Read the dataset (ensure the file is in your working directory)
data <- read_excel("dataset.xlsx")
setwd("~/Optiver-Challenge/excel-editing/raw ")
``
# Read the dataset (ensure the file is in your working directory)
data <- read_excel("dataset.xlsx")
# Convert the date column to Date type (adjust the format if needed)
data$date <- as.Date(data$date)
# Define the target variable name as it appears in your dataset
target_col <- "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average"
# Define predictor names by excluding the date and target columns
predictor_names <- setdiff(names(data), c("date", target_col))
# Create the matrix of predictors and ensure column names are set
X <- as.matrix(data[, predictor_names])
colnames(X) <- predictor_names
# Extract the target variable
y <- data[[target_col]]
# Create a DMatrix for xgboost training
dtrain <- xgb.DMatrix(data = X, label = y)
# Check for missing values in the target column
sum(is.na(data[[target_col]]))
# Read the dataset (ensure the file is in your working directory)
data <- read_excel("dataset.xlsx")
# Convert the date column to Date type (adjust the format if needed)
data$date <- as.Date(data$date)
# Define the target variable name as it appears in your dataset
target_col <- "Average_Price_Eggs_Grade_A_Large_Cost_per_Dozen_in_US_City_Average"
# Define predictor names by excluding the date and target columns
predictor_names <- setdiff(names(data), c("date", target_col))
# Create the matrix of predictors and ensure column names are set
X <- as.matrix(data[, predictor_names])
colnames(X) <- predictor_names
# Extract the target variable
y <- data[[target_col]]
# Check for missing values in the target column
sum(is.na(data[[target_col]]))
